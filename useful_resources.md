# Unit 1 - Introduction to machine learning  
## 1.1 Classification & Regression  
## 1.2 Machine learning paradigms  
### Supervised learning  
### Unsupervised learning  
### Semi-supervised learning  
## Unit 1.3 Reinforcement learning  
---
# Unit 2 - Clustering
## 2.1 Centroid-based clustering = K-Means clustering  
- Expectatiton maximization algorithm
[Youtube - Victor Lavrenko: EM algorithm: how it works](https://www.youtube.com/watch?v=REypj2sy_5U&list=RDCMUCs7alOMRnxhzfKAJ4JjZ7Wg&start_radio=1&t=2)
- [Youtube - Victor Lavrenko: Expectation Maximization: how it works](https://www.youtube.com/watch?v=iQoXFmbXRJA&list=RDCMUCs7alOMRnxhzfKAJ4JjZ7Wg&index=2)  
- [Youtube - Andrew Ng: Lecture 14 - Expectation-Maximization Algorithms | Stanford CS229: Machine Learning (Autumn 2018)](https://www.youtube.com/watch?v=rVfZHWTwXSA)  

## 2.2 Gaussian mixture models clustering  
## 2.3 Hierarchical clustering  
## 2.4 Density-based clustering = DBSCAN  
---
# Unit 3 - Regression  
## 3.1 Linear & nonlinear regression  
## 3.2 Logistic regression   
## 3.3 Quantile regression  
## 3.4 Regularization in regression analysis  
## 3.5 Regression analysis in python  
---
# Unit 4 - Support vector machines  
## 4.1 Introduction to support vector machines - SVM  
## 4.2 Support vector machines for classification  
## 4.3 Support vector machines for regression - SVR  
---
# Unit 5 - Decision trees  
## 5.1 Introduction to decision trees  
## 5.2 Decision tree approaches for classification  
## 5.3 Decision tree for regression  
## 5.4 Decision tree construction  
## 5.5 Decision tree pruning  
## 5.6 Decision trees in ensemble methods  
---
# Unit 6 - Genetic algorithms  
## 6.1 Genetic algorithms definition  
## 6.2 Genetic algorithms phases  
## 6.3 Genetic algorithms example: Knapsack problem  
## 6.4 Genetic algorithms in python  
